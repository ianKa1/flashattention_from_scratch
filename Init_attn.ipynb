{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e900027f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen3ForCausalLM(\n",
      "  (model): Qwen3Model(\n",
      "    (embed_tokens): Embedding(151936, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0-27): 28 x Qwen3DecoderLayer(\n",
      "        (self_attn): Qwen3Attention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "        )\n",
      "        (mlp): Qwen3MLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=6144, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=6144, bias=False)\n",
      "          (down_proj): Linear(in_features=6144, out_features=2048, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
      "    (rotary_emb): Qwen3RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import inspect\n",
    "import sys\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import types\n",
    "from typing import Optional, Union, Unpack, Any\n",
    "\n",
    "# torch.backends.cuda.enable_flash_sdp(False)\n",
    "# torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "\n",
    "model_name = \"Qwen/Qwen3-1.7B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\",   # or \"auto\"\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdd31e3e-c5d3-4066-a3d3-2fc17ea1f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference():\n",
    "    prompt = \"Explain FlashAttention in one sentence.\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=32\n",
    "        )\n",
    "    \n",
    "    print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce4e4959-7060-4b28-8246-dc423fce3544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain FlashAttention in one sentence. FlashAttention is a memory-efficient attention mechanism that enables large-scale training of transformer models by using a flash-like algorithm to process attention queries in a more efficient way,\n"
     ]
    }
   ],
   "source": [
    "test_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba635e96-8029-461f-ba6c-7f1b0d1844ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.qwen3.modeling_qwen3 import ALL_ATTENTION_FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7c4560f-c941-4b66-8f59-9dfaf695a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_attn_forward = ALL_ATTENTION_FUNCTIONS[\"flash_attention_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59f1137b-0d61-4676-9604-234066e4035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patched_flash_attention_forward(\n",
    "    module: torch.nn.Module,\n",
    "    query: torch.Tensor,\n",
    "    key: torch.Tensor,\n",
    "    value: torch.Tensor,\n",
    "    attention_mask: Optional[torch.Tensor],\n",
    "    dropout: float = 0.0,\n",
    "    scaling: Optional[float] = None,\n",
    "    sliding_window: Optional[int] = None,\n",
    "    softcap: Optional[float] = None,\n",
    "    **kwargs,\n",
    ") -> tuple[torch.Tensor, None]:\n",
    "\n",
    "    print(\"\\n===== FlashAttention Backend Debug =====\")\n",
    "\n",
    "    print(\"module:\", type(module))\n",
    "    print(\"dropout:\", dropout)\n",
    "    print(\"scaling:\", scaling)\n",
    "    print(\"sliding_window:\", sliding_window)\n",
    "    print(\"softcap:\", softcap)\n",
    "\n",
    "    print(\"\\n--- Tensor inputs ---\")\n",
    "    print(\"query:\", query.shape, query.dtype, query.device)\n",
    "    print(\"key:  \", key.shape, key.dtype, key.device)\n",
    "    print(\"value:\", value.shape, value.dtype, value.device)\n",
    "\n",
    "    if attention_mask is None:\n",
    "        print(\"attention_mask: None\")\n",
    "    else:\n",
    "        print(\n",
    "            \"attention_mask:\",\n",
    "            attention_mask.shape,\n",
    "            attention_mask.dtype,\n",
    "            attention_mask.device,\n",
    "        )\n",
    "\n",
    "    print(\"\\n--- kwargs ---\")\n",
    "    if not kwargs:\n",
    "        print(\"kwargs: (empty)\")\n",
    "    else:\n",
    "        for k, v in kwargs.items():\n",
    "            if torch.is_tensor(v):\n",
    "                print(f\"{k}: Tensor(shape={v.shape}, dtype={v.dtype}, device={v.device})\")\n",
    "            else:\n",
    "                print(f\"{k}: {v} (type={type(v)})\")\n",
    "\n",
    "    print(\"===== End Debug =====\\n\")\n",
    "    attn_output, _ = org_attn_forward(module, query, key, value, attention_mask, dropout, scaling, sliding_window, softcap, **kwargs)\n",
    "    return attn_output, None\n",
    "\n",
    "ALL_ATTENTION_FUNCTIONS['my_flash'] = patched_flash_attention_forward\n",
    "model.config._attn_implementation = 'my_flash'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b972f73-9afc-4981-aa20-9b8170c2395a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 8, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 8, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 8]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 9, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 10, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 11, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 12, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 13, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 14, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 15, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 16, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 17, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 18, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 19, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 20, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 21, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 22, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 23, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 24, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 25, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 26, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 27, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 28, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 29, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 30, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 31, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 32, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 33, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 34, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 35, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 36, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 37, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 38, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "\n",
      "===== FlashAttention Backend Debug =====\n",
      "module: <class 'transformers.models.qwen3.modeling_qwen3.Qwen3Attention'>\n",
      "dropout: 0.0\n",
      "scaling: 0.08838834764831845\n",
      "sliding_window: None\n",
      "softcap: None\n",
      "\n",
      "--- Tensor inputs ---\n",
      "query: torch.Size([1, 16, 1, 128]) torch.float16 cuda:0\n",
      "key:   torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "value: torch.Size([1, 8, 39, 128]) torch.float16 cuda:0\n",
      "attention_mask: None\n",
      "\n",
      "--- kwargs ---\n",
      "position_ids: Tensor(shape=torch.Size([1, 1]), dtype=torch.int64, device=cuda:0)\n",
      "use_cache: True (type=<class 'bool'>)\n",
      "===== End Debug =====\n",
      "\n",
      "Explain FlashAttention in one sentence. FlashAttention is a technique that enables efficient computation of attention in large-scale models by using a flash-like algorithm to reduce the time complexity of the attention operation, which\n"
     ]
    }
   ],
   "source": [
    "test_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d443ff-461e-4e97-b1fd-304dc06cf550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45bd410-68b2-4eba-b986-0059d0d01132",
   "metadata": {},
   "outputs": [],
   "source": [
    "flash_attention_2: <function flash_attention_forward at 0x78aab3d299e0>\n",
    "def flash_attention_forward(\n",
    "    module: torch.nn.Module,\n",
    "    query: torch.Tensor,\n",
    "    key: torch.Tensor,\n",
    "    value: torch.Tensor,\n",
    "    attention_mask: Optional[torch.Tensor],\n",
    "    dropout: float = 0.0,\n",
    "    scaling: Optional[float] = None,\n",
    "    sliding_window: Optional[int] = None,\n",
    "    softcap: Optional[float] = None,\n",
    "    **kwargs,\n",
    ") -> tuple[torch.Tensor, None]:\n",
    "    if kwargs.get(\"output_attentions\", False) or kwargs.get(\"head_mask\") is not None:\n",
    "        logger.warning_once(\n",
    "            \"`flash_attention_2` does not support `output_attentions=True` or `head_mask`.\"\n",
    "            \" Please set your attention to `eager` if you want any of these features.\"\n",
    "        )\n",
    "\n",
    "    # This is before the transpose\n",
    "    seq_len = query.shape[2]\n",
    "\n",
    "    if any(dim == 0 for dim in query.shape):\n",
    "        raise ValueError(\n",
    "            \"Tensor query has shape  with a zero dimension.\\n\"\n",
    "            \"FlashAttention does not support inputs with dim=0.\\n\"\n",
    "            \"Please check your input shapes or use SDPA instead.\"\n",
    "        )\n",
    "    # FA2 uses non-transposed inputs\n",
    "    query = query.transpose(1, 2)\n",
    "    key = key.transpose(1, 2)\n",
    "    value = value.transpose(1, 2)\n",
    "\n",
    "    # In PEFT, usually we cast the layer norms in float32 for training stability reasons\n",
    "    # therefore the input hidden states gets silently casted in float32. Hence, we need\n",
    "    # cast them back in the correct dtype just to be sure everything works as expected.\n",
    "    # This might slowdown training & inference so it is recommended to not cast the LayerNorms\n",
    "    # in fp32. (usually our RMSNorm modules handle it correctly)\n",
    "    target_dtype = None\n",
    "    if query.dtype == torch.float32:\n",
    "        if torch.is_autocast_enabled():\n",
    "            target_dtype = torch.get_autocast_gpu_dtype()\n",
    "        # Handle the case where the model is quantized\n",
    "        elif hasattr(module.config, \"_pre_quantization_dtype\"):\n",
    "            target_dtype = module.config._pre_quantization_dtype\n",
    "        else:\n",
    "            target_dtype = next(layer for layer in module.modules() if isinstance(layer, torch.nn.Linear)).weight.dtype\n",
    "\n",
    "    # Instead of relying on the value set in the module directly, we use the is_causal passed in kwargs if it is presented\n",
    "    is_causal = kwargs.pop(\"is_causal\", None)\n",
    "    if is_causal is None:\n",
    "        is_causal = module.is_causal\n",
    "\n",
    "    attn_output = _flash_attention_forward(\n",
    "        query,\n",
    "        key,\n",
    "        value,\n",
    "        attention_mask,\n",
    "        query_length=seq_len,\n",
    "        is_causal=is_causal,\n",
    "        dropout=dropout,\n",
    "        softmax_scale=scaling,\n",
    "        sliding_window=sliding_window,\n",
    "        softcap=softcap,\n",
    "        use_top_left_mask=_use_top_left_mask,\n",
    "        target_dtype=target_dtype,\n",
    "        attn_implementation=module.config._attn_implementation,\n",
    "        layer_idx=module.layer_idx if hasattr(module, \"layer_idx\") else None,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    return attn_output, None\n",
    "\n",
    "sdpa: <function sdpa_attention_forward at 0x78aab3c22160>\n",
    "def sdpa_attention_forward(\n",
    "    module: torch.nn.Module,\n",
    "    query: torch.Tensor,\n",
    "    key: torch.Tensor,\n",
    "    value: torch.Tensor,\n",
    "    attention_mask: Optional[torch.Tensor],\n",
    "    dropout: float = 0.0,\n",
    "    scaling: Optional[float] = None,\n",
    "    is_causal: Optional[bool] = None,\n",
    "    **kwargs,\n",
    ") -> tuple[torch.Tensor, None]:\n",
    "    if kwargs.get(\"output_attentions\", False) or kwargs.get(\"head_mask\") is not None:\n",
    "        logger.warning_once(\n",
    "            \"`sdpa` attention does not support `output_attentions=True` or `head_mask`.\"\n",
    "            \" Please set your attention to `eager` if you want any of these features.\"\n",
    "        )\n",
    "    sdpa_kwargs = {}\n",
    "    if hasattr(module, \"num_key_value_groups\"):\n",
    "        if not use_gqa_in_sdpa(attention_mask, key):\n",
    "            key = repeat_kv(key, module.num_key_value_groups)\n",
    "            value = repeat_kv(value, module.num_key_value_groups)\n",
    "        else:\n",
    "            sdpa_kwargs = {\"enable_gqa\": True}\n",
    "\n",
    "    if attention_mask is not None and attention_mask.ndim == 4:\n",
    "        attention_mask = attention_mask[:, :, :, : key.shape[-2]]\n",
    "\n",
    "    # We dispatch to SDPA's Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment\n",
    "    # in SDPA to support both torch.compile's dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.\n",
    "    # Note that it is important to check first for the shape, otherwise compile will fail with `argument 'is_causal' must be bool, not SymBool`\n",
    "    if is_causal is None:\n",
    "        # The last condition is for encoder (decoder) models which specify this by passing their own `is_causal` flag\n",
    "        # This is mainly due to those models having mixed implementations for encoder, decoder, and encoder-decoder attns\n",
    "        is_causal = query.shape[2] > 1 and attention_mask is None and getattr(module, \"is_causal\", True)\n",
    "\n",
    "    # Shapes (e.g. query.shape[2]) are tensors during jit tracing, resulting in `is_causal` being a tensor.\n",
    "    # We convert it to a bool for the SDPA kernel that only accepts bools.\n",
    "    if torch.jit.is_tracing() and isinstance(is_causal, torch.Tensor):\n",
    "        is_causal = is_causal.item()\n",
    "\n",
    "    # When `is_causal = False` and the `attention_mask` is not of boolean type, the Ascend NPU's SDPA interface cannot utilize the FlashAttentionScore operator，\n",
    "    # and falls back to small-operator concatenation. To invoke the FlashAttentionScore, the attention_mask must be converted to boolean type.\n",
    "    # This adaptation ensures the `attention_mask` meets the requirement for using FlashAttentionScore.\n",
    "    if _is_torch_npu_available:\n",
    "        if attention_mask is not None and attention_mask.dtype != torch.bool:\n",
    "            # Convert to boolean type, making sdpa to force call FlashAttentionScore to improve performance.\n",
    "            attention_mask = torch.logical_not(attention_mask.bool()).to(query.device)\n",
    "\n",
    "    attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
    "        query,\n",
    "        key,\n",
    "        value,\n",
    "        attn_mask=attention_mask,\n",
    "        dropout_p=dropout,\n",
    "        scale=scaling,\n",
    "        is_causal=is_causal,\n",
    "        **sdpa_kwargs,\n",
    "    )\n",
    "    attn_output = attn_output.transpose(1, 2).contiguous()\n",
    "\n",
    "    return attn_output, None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
